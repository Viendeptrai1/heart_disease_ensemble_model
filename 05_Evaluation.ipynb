{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05. Final Evaluation & Summary\n",
                "\n",
                "## Muc tieu\n",
                "- Tong hop ket qua tat ca models\n",
                "- Danh gia chi tiet best model\n",
                "- Tao cac bieu do cho bao cao\n",
                "- Xuat final model de ung dung"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import thu vien\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, confusion_matrix, classification_report,\n",
                "    roc_curve, precision_recall_curve\n",
                ")\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load du lieu va models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load du lieu test\n",
                "X_test = np.load('data/X_test.npy')\n",
                "y_test = np.load('data/y_test.npy')\n",
                "feature_names = np.load('data/feature_names.npy', allow_pickle=True)\n",
                "\n",
                "print(f\"Test set: {X_test.shape}\")\n",
                "\n",
                "# Load ket qua\n",
                "single_results = pd.read_csv('outputs/single_models_results.csv', index_col=0)\n",
                "ensemble_results = pd.read_csv('outputs/ensemble_models_results.csv', index_col=0)\n",
                "ablation_results = pd.read_csv('outputs/ablation_results.csv', index_col=0)\n",
                "\n",
                "# Tim best model dua tren F1 score\n",
                "# Loc bo 'Best Single Model' neu co\n",
                "ensemble_clean = ensemble_results[ensemble_results.index != 'Best Single Model']\n",
                "best_ensemble_name = ensemble_clean['f1'].idxmax()\n",
                "best_single_name = single_results['f1'].idxmax()\n",
                "\n",
                "# So sanh F1 cua ensemble tot nhat voi single tot nhat\n",
                "if ensemble_clean.loc[best_ensemble_name, 'f1'] >= single_results.loc[best_single_name, 'f1']:\n",
                "    best_model_file = f'models/ensemble_{best_ensemble_name.lower()}.pkl'\n",
                "    best_name = best_ensemble_name\n",
                "else:\n",
                "    best_model_file = f'models/single_{best_single_name.lower()}.pkl'\n",
                "    best_name = best_single_name\n",
                "\n",
                "best_model = joblib.load(best_model_file)\n",
                "print(f\"Best model: {best_name} (loaded from {best_model_file})\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Tong hop ket qua tat ca Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ket hop single va ensemble results\n",
                "single_results['type'] = 'Single'\n",
                "ensemble_clean = ensemble_results[ensemble_results.index != 'Best Single Model'].copy()\n",
                "ensemble_clean['type'] = 'Ensemble'\n",
                "\n",
                "all_results = pd.concat([single_results, ensemble_clean])\n",
                "all_results = all_results.sort_values('f1', ascending=False)\n",
                "\n",
                "print(\"TONG HOP KET QUA TAT CA MODELS:\")\n",
                "print(\"=\"*80)\n",
                "print(all_results[['type', 'accuracy', 'recall', 'f1', 'roc_auc']].to_string())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization tong hop\n",
                "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
                "\n",
                "metrics = ['accuracy', 'recall', 'f1', 'roc_auc']\n",
                "titles = ['Accuracy', 'Recall', 'F1-Score', 'ROC-AUC']\n",
                "\n",
                "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
                "    ax = axes[i // 2, i % 2]\n",
                "    \n",
                "    # Sort theo metric\n",
                "    sorted_results = all_results.sort_values(metric, ascending=True)\n",
                "    \n",
                "    # Mau theo type\n",
                "    colors = ['#e74c3c' if t == 'Ensemble' else '#3498db' for t in sorted_results['type']]\n",
                "    \n",
                "    bars = ax.barh(sorted_results.index, sorted_results[metric], color=colors, edgecolor='black')\n",
                "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
                "    ax.set_xlabel(metric.capitalize())\n",
                "    \n",
                "    # Them gia tri\n",
                "    for bar, val in zip(bars, sorted_results[metric]):\n",
                "        if pd.notna(val):\n",
                "            ax.text(val + 0.002, bar.get_y() + bar.get_height()/2, \n",
                "                    f'{val:.4f}', va='center', fontsize=9)\n",
                "\n",
                "# Legend\n",
                "from matplotlib.patches import Patch\n",
                "legend_elements = [\n",
                "    Patch(facecolor='#3498db', label='Single Model'),\n",
                "    Patch(facecolor='#e74c3c', label='Ensemble Model')\n",
                "]\n",
                "fig.legend(handles=legend_elements, loc='upper center', ncol=2, fontsize=12)\n",
                "\n",
                "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
                "plt.savefig('outputs/17_all_models_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Danh gia chi tiet Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict voi best model\n",
                "y_pred = best_model.predict(X_test)\n",
                "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Tim ten best model\n",
                "best_name = ensemble_results['f1'].idxmax()\n",
                "if best_name == 'Best Single Model':\n",
                "    best_name = single_results['f1'].idxmax()\n",
                "\n",
                "print(f\"\\nBEST MODEL: {best_name}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classification Report chi tiet\n",
                "print(\"\\nCLASSIFICATION REPORT:\")\n",
                "print(\"-\"*60)\n",
                "print(classification_report(y_test, y_pred, target_names=['Khong benh', 'Co benh tim']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix chi tiet\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Raw counts\n",
                "ax1 = axes[0]\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
                "            xticklabels=['Khong benh (0)', 'Co benh (1)'],\n",
                "            yticklabels=['Khong benh (0)', 'Co benh (1)'])\n",
                "ax1.set_title(f'Confusion Matrix - {best_name}\\n(So luong)', fontsize=12, fontweight='bold')\n",
                "ax1.set_ylabel('Thuc te')\n",
                "ax1.set_xlabel('Du doan')\n",
                "\n",
                "# Percentages\n",
                "ax2 = axes[1]\n",
                "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
                "sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues', ax=ax2,\n",
                "            xticklabels=['Khong benh (0)', 'Co benh (1)'],\n",
                "            yticklabels=['Khong benh (0)', 'Co benh (1)'])\n",
                "ax2.set_title(f'Confusion Matrix - {best_name}\\n(Ty le %)', fontsize=12, fontweight='bold')\n",
                "ax2.set_ylabel('Thuc te')\n",
                "ax2.set_xlabel('Du doan')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('outputs/18_best_model_confusion.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# Phan tich confusion matrix\n",
                "tn, fp, fn, tp = cm.ravel()\n",
                "print(f\"\\nPHAN TICH CONFUSION MATRIX:\")\n",
                "print(f\"  True Negative (TN):  {tn:,} - Du doan dung nguoi khong benh\")\n",
                "print(f\"  False Positive (FP): {fp:,} - Du doan nham nguoi khoe la benh\")\n",
                "print(f\"  False Negative (FN): {fn:,} - Bo sot nguoi benh (NGUY HIEM!)\")\n",
                "print(f\"  True Positive (TP):  {tp:,} - Du doan dung nguoi benh\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve va Precision-Recall Curve\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# ROC Curve\n",
                "ax1 = axes[0]\n",
                "fpr, tpr, thresholds_roc = roc_curve(y_test, y_proba)\n",
                "auc = roc_auc_score(y_test, y_proba)\n",
                "\n",
                "ax1.plot(fpr, tpr, 'b-', linewidth=2, label=f'{best_name} (AUC={auc:.4f})')\n",
                "ax1.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')\n",
                "ax1.fill_between(fpr, tpr, alpha=0.3)\n",
                "ax1.set_xlabel('False Positive Rate', fontsize=12)\n",
                "ax1.set_ylabel('True Positive Rate', fontsize=12)\n",
                "ax1.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
                "ax1.legend(loc='lower right')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# Precision-Recall Curve\n",
                "ax2 = axes[1]\n",
                "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
                "\n",
                "ax2.plot(recall_curve, precision_curve, 'g-', linewidth=2, label=best_name)\n",
                "ax2.axhline(y=0.5, color='red', linestyle='--', label='Baseline')\n",
                "ax2.set_xlabel('Recall', fontsize=12)\n",
                "ax2.set_ylabel('Precision', fontsize=12)\n",
                "ax2.set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
                "ax2.legend(loc='lower left')\n",
                "ax2.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('outputs/19_best_model_curves.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Phan tich sai so (Error Analysis)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Phan tich cac truong hop du doan sai\n",
                "X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
                "X_test_df['y_true'] = y_test\n",
                "X_test_df['y_pred'] = y_pred\n",
                "X_test_df['y_proba'] = y_proba\n",
                "X_test_df['correct'] = (y_test == y_pred)\n",
                "\n",
                "# False Negatives (bo sot benh - nguy hiem nhat)\n",
                "fn_cases = X_test_df[(X_test_df['y_true'] == 1) & (X_test_df['y_pred'] == 0)]\n",
                "\n",
                "# False Positives (bao nham benh)\n",
                "fp_cases = X_test_df[(X_test_df['y_true'] == 0) & (X_test_df['y_pred'] == 1)]\n",
                "\n",
                "print(f\"FALSE NEGATIVES (Bo sot benh): {len(fn_cases)}\")\n",
                "print(f\"FALSE POSITIVES (Bao nham benh): {len(fp_cases)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# So sanh dac diem cua cac nhom\n",
                "print(\"\\nSO SANH DAC DIEM CAC NHOM:\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "analysis_features = ['age_years', 'ap_hi', 'ap_lo', 'bmi', 'cholesterol']\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'True Positive': X_test_df[(X_test_df['y_true'] == 1) & (X_test_df['y_pred'] == 1)][analysis_features].mean(),\n",
                "    'False Negative': fn_cases[analysis_features].mean() if len(fn_cases) > 0 else None,\n",
                "    'True Negative': X_test_df[(X_test_df['y_true'] == 0) & (X_test_df['y_pred'] == 0)][analysis_features].mean(),\n",
                "    'False Positive': fp_cases[analysis_features].mean() if len(fp_cases) > 0 else None,\n",
                "})\n",
                "\n",
                "print(comparison.round(3).to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Threshold Optimization (Tang Recall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Voi bai toan y te, chung ta muon tang Recall (giam bo sot benh)\n",
                "# Co the ha threshold de tang Recall\n",
                "\n",
                "thresholds = np.arange(0.3, 0.7, 0.05)\n",
                "threshold_results = []\n",
                "\n",
                "for thresh in thresholds:\n",
                "    y_pred_thresh = (y_proba >= thresh).astype(int)\n",
                "    \n",
                "    result = {\n",
                "        'threshold': thresh,\n",
                "        'accuracy': accuracy_score(y_test, y_pred_thresh),\n",
                "        'precision': precision_score(y_test, y_pred_thresh),\n",
                "        'recall': recall_score(y_test, y_pred_thresh),\n",
                "        'f1': f1_score(y_test, y_pred_thresh),\n",
                "    }\n",
                "    threshold_results.append(result)\n",
                "\n",
                "thresh_df = pd.DataFrame(threshold_results)\n",
                "print(\"\\nKET QUA THEO CAC THRESHOLD KHAC NHAU:\")\n",
                "print(thresh_df.round(4).to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization threshold optimization\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "\n",
                "ax.plot(thresh_df['threshold'], thresh_df['accuracy'], 'o-', label='Accuracy', linewidth=2)\n",
                "ax.plot(thresh_df['threshold'], thresh_df['precision'], 's-', label='Precision', linewidth=2)\n",
                "ax.plot(thresh_df['threshold'], thresh_df['recall'], '^-', label='Recall', linewidth=2)\n",
                "ax.plot(thresh_df['threshold'], thresh_df['f1'], 'd-', label='F1-Score', linewidth=2)\n",
                "\n",
                "ax.axvline(x=0.5, color='gray', linestyle='--', label='Default (0.5)')\n",
                "\n",
                "ax.set_xlabel('Threshold', fontsize=12)\n",
                "ax.set_ylabel('Score', fontsize=12)\n",
                "ax.set_title('Metrics theo Threshold', fontsize=14, fontweight='bold')\n",
                "ax.legend(loc='best')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('outputs/20_threshold_optimization.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# Tim threshold toi uu cho Recall > 0.75\n",
                "high_recall = thresh_df[thresh_df['recall'] >= 0.75]\n",
                "if len(high_recall) > 0:\n",
                "    best_thresh = high_recall.loc[high_recall['f1'].idxmax()]\n",
                "    print(f\"\\nThreshold toi uu (Recall >= 0.75): {best_thresh['threshold']:.2f}\")\n",
                "    print(f\"  Recall: {best_thresh['recall']:.4f}\")\n",
                "    print(f\"  F1: {best_thresh['f1']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Tao bang tong ket cho bao cao"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bang 1: So sanh Single Models\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"BANG 1: KET QUA CAC SINGLE MODELS\")\n",
                "print(\"=\"*70)\n",
                "single_summary = single_results[['accuracy', 'precision', 'recall', 'f1', 'roc_auc']].round(4)\n",
                "print(single_summary.to_string())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bang 2: So sanh Ensemble Models\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"BANG 2: KET QUA CAC ENSEMBLE MODELS\")\n",
                "print(\"=\"*70)\n",
                "ensemble_summary = ensemble_clean[['accuracy', 'precision', 'recall', 'f1', 'roc_auc']].round(4)\n",
                "print(ensemble_summary.to_string())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bang 3: Ablation Study\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"BANG 3: KET QUA ABLATION STUDY\")\n",
                "print(\"=\"*70)\n",
                "ablation_summary = ablation_results[['accuracy', 'recall', 'f1']].round(4)\n",
                "print(ablation_summary.to_string())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Luu cac bang\n",
                "single_summary.to_csv('outputs/table1_single_models.csv')\n",
                "ensemble_summary.to_csv('outputs/table2_ensemble_models.csv')\n",
                "ablation_summary.to_csv('outputs/table3_ablation.csv')\n",
                "\n",
                "print(\"\\nDa luu cac bang:\")\n",
                "print(\"  outputs/table1_single_models.csv\")\n",
                "print(\"  outputs/table2_ensemble_models.csv\")\n",
                "print(\"  outputs/table3_ablation.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Export Final Model cho ung dung"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Luu final model voi metadata\n",
                "final_model_package = {\n",
                "    'model': best_model,\n",
                "    'model_name': best_name,\n",
                "    'feature_names': list(feature_names),\n",
                "    'metrics': {\n",
                "        'accuracy': accuracy_score(y_test, y_pred),\n",
                "        'precision': precision_score(y_test, y_pred),\n",
                "        'recall': recall_score(y_test, y_pred),\n",
                "        'f1': f1_score(y_test, y_pred),\n",
                "        'roc_auc': roc_auc_score(y_test, y_proba)\n",
                "    },\n",
                "    'scaler_path': 'models/scaler.pkl',\n",
                "    'threshold': 0.5\n",
                "}\n",
                "\n",
                "joblib.dump(final_model_package, 'models/final_model_package.pkl')\n",
                "print(\"Da luu final model package: models/final_model_package.pkl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tao ham predict de su dung trong ung dung\n",
                "def predict_heart_disease(patient_data, model_path='models/final_model_package.pkl'):\n",
                "    \"\"\"\n",
                "    Du doan benh tim cho benh nhan moi.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    patient_data : dict\n",
                "        Thong tin benh nhan voi cac key:\n",
                "        - age_years: Tuoi (nam)\n",
                "        - gender: Gioi tinh (1: Nu, 2: Nam)\n",
                "        - height: Chieu cao (cm)\n",
                "        - weight: Can nang (kg)\n",
                "        - ap_hi: Huyet ap tam thu\n",
                "        - ap_lo: Huyet ap tam truong\n",
                "        - cholesterol: Muc cholesterol (1, 2, 3)\n",
                "        - gluc: Muc glucose (1, 2, 3)\n",
                "        - smoke: Hut thuoc (0, 1)\n",
                "        - alco: Uong ruou (0, 1)\n",
                "        - active: Hoat dong the chat (0, 1)\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    dict: Ket qua du doan\n",
                "    \"\"\"\n",
                "    import joblib\n",
                "    import numpy as np\n",
                "    \n",
                "    # Load model\n",
                "    package = joblib.load(model_path)\n",
                "    model = package['model']\n",
                "    feature_names = package['feature_names']\n",
                "    scaler = joblib.load(package['scaler_path'])\n",
                "    \n",
                "    # Tinh cac derived features\n",
                "    bmi = patient_data['weight'] / ((patient_data['height'] / 100) ** 2)\n",
                "    pulse_pressure = patient_data['ap_hi'] - patient_data['ap_lo']\n",
                "    map_value = (patient_data['ap_hi'] + 2 * patient_data['ap_lo']) / 3\n",
                "    \n",
                "    # Tao feature vector\n",
                "    features = np.array([[\n",
                "        patient_data['age_years'],\n",
                "        patient_data['gender'],\n",
                "        patient_data['height'],\n",
                "        patient_data['weight'],\n",
                "        patient_data['ap_hi'],\n",
                "        patient_data['ap_lo'],\n",
                "        patient_data['cholesterol'],\n",
                "        patient_data['gluc'],\n",
                "        patient_data['smoke'],\n",
                "        patient_data['alco'],\n",
                "        patient_data['active'],\n",
                "        bmi,\n",
                "        pulse_pressure,\n",
                "        map_value\n",
                "    ]])\n",
                "    \n",
                "    # Scale features\n",
                "    features_to_scale_idx = [0, 2, 3, 4, 5, 11, 12, 13]\n",
                "    features_scaled = features.copy()\n",
                "    features_scaled[:, features_to_scale_idx] = scaler.transform(features[:, features_to_scale_idx])\n",
                "    \n",
                "    # Predict\n",
                "    prediction = model.predict(features_scaled)[0]\n",
                "    probability = model.predict_proba(features_scaled)[0, 1]\n",
                "    \n",
                "    return {\n",
                "        'prediction': int(prediction),\n",
                "        'label': 'Co nguy co benh tim' if prediction == 1 else 'Khong co nguy co',\n",
                "        'probability': float(probability),\n",
                "        'risk_level': 'Cao' if probability > 0.7 else 'Trung binh' if probability > 0.5 else 'Thap'\n",
                "    }\n",
                "\n",
                "print(\"Da dinh nghia ham predict_heart_disease()\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test thu ham predict\n",
                "example_patient = {\n",
                "    'age_years': 55,\n",
                "    'gender': 2,  # Nam\n",
                "    'height': 170,\n",
                "    'weight': 85,\n",
                "    'ap_hi': 150,  # Huyet ap cao\n",
                "    'ap_lo': 95,\n",
                "    'cholesterol': 2,  # Cao\n",
                "    'gluc': 1,  # Binh thuong\n",
                "    'smoke': 1,  # Hut thuoc\n",
                "    'alco': 0,\n",
                "    'active': 0  # Khong tap the duc\n",
                "}\n",
                "\n",
                "print(\"\\nVD Du doan cho benh nhan:\")\n",
                "print(f\"  Tuoi: {example_patient['age_years']}, Nam\")\n",
                "print(f\"  Chieu cao/Can nang: {example_patient['height']}cm / {example_patient['weight']}kg\")\n",
                "print(f\"  Huyet ap: {example_patient['ap_hi']}/{example_patient['ap_lo']}\")\n",
                "print(f\"  Cholesterol: Cao, Hut thuoc: Co\")\n",
                "\n",
                "# result = predict_heart_disease(example_patient)\n",
                "# print(f\"\\nKet qua: {result['label']}\")\n",
                "# print(f\"Xac suat: {result['probability']:.2%}\")\n",
                "# print(f\"Muc do nguy co: {result['risk_level']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Tong ket cuoi cung"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"TONG KET DU AN CHAN DOAN BENH TIM BANG ENSEMBLE MODEL\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(\"\\n1. DU LIEU:\")\n",
                "print(\"   - Dataset: Cardiovascular Disease\")\n",
                "print(\"   - So mau: ~70,000\")\n",
                "print(\"   - Features: 14 (bao gom derived features)\")\n",
                "print(\"   - Chia du lieu: 70/15/15 (Train/Val/Test)\")\n",
                "\n",
                "print(\"\\n2. SINGLE MODELS (6 models):\")\n",
                "print(\"   - Logistic Regression, KNN, Naive Bayes, Decision Tree\")\n",
                "print(\"   - MLP Classifier, SGDClassifier (Linear SVM)\")\n",
                "print(\"   - Hyperparameter tuning: Optuna (50 trials)\")\n",
                "print(\"   - Cross-validation: 5-Fold Stratified\")\n",
                "\n",
                "print(\"\\n3. ENSEMBLE MODELS:\")\n",
                "print(\"   Base Ensemble: RF, XGB, LightGBM, Bagging SVM, Nystroem+SGD\")\n",
                "print(\"   Advanced: Hard Voting, Soft Voting\")\n",
                "print(\"   - Stacking (LR meta, XGB meta), Blending\")\n",
                "\n",
                "print(f\"\\n4. BEST MODEL: {best_name}\")\n",
                "best_metrics = ensemble_results.loc[ensemble_results['f1'].idxmax()]\n",
                "print(f\"   - Accuracy:  {best_metrics['accuracy']:.4f}\")\n",
                "print(f\"   - Precision: {best_metrics['precision']:.4f}\")\n",
                "print(f\"   - Recall:    {best_metrics['recall']:.4f}\")\n",
                "print(f\"   - F1-Score:  {best_metrics['f1']:.4f}\")\n",
                "print(f\"   - ROC-AUC:   {best_metrics['roc_auc']:.4f}\")\n",
                "\n",
                "print(\"\\n5. ABLATION STUDY:\")\n",
                "print(\"   - Chung minh moi base model deu dong gop vao ket qua\")\n",
                "print(\"   - Features quan trong nhat: ap_hi, ap_lo, age_years, bmi\")\n",
                "\n",
                "print(\"\\n6. FILES DA TAO:\")\n",
                "print(\"   - Notebooks: 01_EDA, 02_Preprocessing, 03_SingleModels, 04_EnsembleModels, 05_Evaluation\")\n",
                "print(\"   - Models: models/final_model_package.pkl\")\n",
                "print(\"   - Outputs: 20+ bieu do va bang ket qua\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"DU AN HOAN THANH!\")\n",
                "print(\"=\"*70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "py311_dev",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
